{
  "task_type": "llm",
  "input_dim": 512,
  "hidden_dim": 128,
  "output_dim": 50257,
  "liquid_units": 64,
  "liquid_backbone": "cfc",
  "spiking_units": 32,
  "spike_threshold": 0.8,
  "beta": 0.9,
  "num_spike_steps": 32,
  "num_layers": 2,
  "num_attention_heads": 2,
  "embedding_dim": 512,
  "max_position_embeddings": 128,
  "vocab_size": 50257,
  "conv_channels": null,
  "conv_kernel_sizes": null,
  "conv_strides": null,
  "conv_padding": null,
  "dropout": 0.1,
  "attention_dropout": 0.1,
  "embedding_dropout": 0.1,
  "sequence_length": 16,
  "batch_size": 2,
  "learning_rate": 0.001,
  "weight_decay": 0.01,
  "gradient_clip": 1.0,
  "mixed_precision": true,
  "device": "cuda",
  "seed": 42,
  "num_epochs": 1,
  "layer_norm_eps": 1e-05,
  "initializer_range": 0.02,
  "use_cache": true
}